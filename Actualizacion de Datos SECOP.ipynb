{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c3763f-0824-49da-9dcd-906b39b91b63",
   "metadata": {},
   "source": [
    "# Actualizacion de la base\n",
    "\n",
    "Se busca tener actualizada de forma diaria la base para asi poder mantener un analisis enfocado al momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f9cd64-399a-4b17-bebf-13c4cd42b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Bases y repositorio de los lotes \n",
    "ruta_parquet = r\"C:\\Users\\aleja\\OneDrive\\Escritorio\\Consultoria\\desarrollo_social_y_economico\\Lotes\\lote_2025_S2.parquet\"\n",
    "chunk_size = 50000\n",
    "dataset_id = \"p6dx-8zbt\"\n",
    "url = f\"https://www.datos.gov.co/resource/{dataset_id}.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebd2d79b-b008-471e-a603-413e6560dd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actualizando desde: 2025-09-10T00:00:00 hasta: 2025-09-09T23:59:59\n"
     ]
    }
   ],
   "source": [
    "# Ãšltimo semestre conocido\n",
    "df_existing = pd.read_parquet(ruta_parquet)\n",
    "df_existing[\"fecha_de_publicacion_del\"] = pd.to_datetime(df_existing[\"fecha_de_publicacion_del\"], errors=\"coerce\", utc=True)\n",
    "\n",
    "# --- 2. Definir el rango a actualizar ---\n",
    "ultima_fecha = df_existing[\"fecha_de_publicacion_del\"].max()\n",
    "fecha_inicio = (ultima_fecha + timedelta(days=1)).strftime(\"%Y-%m-%dT00:00:00\")\n",
    "fecha_fin = pd.Timestamp.today().strftime(\"%Y-%m-%dT23:59:59\")\n",
    "\n",
    "print(f\"Actualizando desde: {fecha_inicio} hasta: {fecha_fin}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c22e12-c37d-4756-9903-ac7c5e06c9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… No hay registros nuevos para actualizar.\n",
      "\n",
      "ðŸ“Š Ãšltimos dÃ­as y cantidad de registros:\n",
      "fecha\n",
      "2025-09-09     3\n",
      "2025-09-08    21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "nuevos_dfs = []\n",
    "\n",
    "while True:\n",
    "    params = {\n",
    "        \"$limit\": chunk_size,\n",
    "        \"$offset\": offset,\n",
    "        \"$order\": \"fecha_de_publicacion_del ASC\",\n",
    "        \"$where\": f\"fecha_de_publicacion_del between '{fecha_inicio}' and '{fecha_fin}'\"\n",
    "    }\n",
    "    resp = requests.get(url, params=params)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    if not data:\n",
    "        break\n",
    "    df_chunk = pd.DataFrame(data)\n",
    "    df_chunk[\"fecha_de_publicacion_del\"] = pd.to_datetime(df_chunk[\"fecha_de_publicacion_del\"], errors=\"coerce\", utc=True)\n",
    "    nuevos_dfs.append(df_chunk)\n",
    "    offset += chunk_size\n",
    "    print(f\"  âœ… TraÃ­dos {len(df_chunk):,} registros (offset {offset})\")\n",
    "\n",
    "# --- 4. Concatenar con los existentes ---\n",
    "if nuevos_dfs:\n",
    "    df_new = pd.concat(nuevos_dfs, ignore_index=True)\n",
    "    df_actualizado = pd.concat([df_existing, df_new], ignore_index=True)\n",
    "    df_actualizado.to_parquet(ruta_parquet, engine=\"pyarrow\", index=False)\n",
    "    print(f\"\\nâœ… ActualizaciÃ³n completada. Total registros: {len(df_actualizado):,}\")\n",
    "else:\n",
    "    df_actualizado = df_existing\n",
    "    print(\"\\nâœ… No hay registros nuevos para actualizar.\")\n",
    "\n",
    "# --- 5. Resumen de los Ãºltimos dÃ­as ---\n",
    "df_actualizado['fecha'] = df_actualizado['fecha_de_publicacion_del'].dt.date\n",
    "ultimos_dos_dias = df_actualizado['fecha'].value_counts().sort_index(ascending=False).head(2)\n",
    "print(\"\\nðŸ“Š Ãšltimos dÃ­as y cantidad de registros:\")\n",
    "print(ultimos_dos_dias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c891b7ef-dc53-405d-b874-535fbb93a4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Notebook copiado a: C:\\Users\\aleja\\OneDrive\\Escritorio\\Consultoria\\desarrollo_social_y_economico\\Lotes\\Actualizacion de Datos SECOP.ipynb\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "origen = \"Actualizacion de Datos SECOP.ipynb\"\n",
    "destino = r\"C:\\Users\\aleja\\OneDrive\\Escritorio\\Consultoria\\desarrollo_social_y_economico\\Lotes\\Actualizacion de Datos SECOP.ipynb\"\n",
    "\n",
    "shutil.copy(origen, destino)\n",
    "print(f\"âœ… Notebook copiado a: {destino}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
